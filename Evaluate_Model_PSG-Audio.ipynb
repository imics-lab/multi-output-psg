{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"139CLD6B5jb_jEIYtiaGsPKyXsFTmFI3q","timestamp":1671333197496},{"file_id":"15mbwS9KgtibP7V2F4hhTbxL6B8LOHo_S","timestamp":1671327775827},{"file_id":"1qbxxBgdIqbUnYw49Suoz183DLrV623AR","timestamp":1671303147189},{"file_id":"1WWh_Y4KVMMIKpK5Bz-40z84lqlbI9yXx","timestamp":1671068082776},{"file_id":"1hYJKDVzbpHO-5N6thG-wpRZ39sm_G7uX","timestamp":1662661463666},{"file_id":"1w4xAQhEWnM_mWGkjz-f3gaJeIfrdnd5h","timestamp":1661457269417}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Khc4g511HMYk"},"source":["#Evaluate Model PSG-Audio\n","This is a follow-on to the individual notebooks used in the fusion repository.\n","\n","My goal is to make a single notebook to run the training and evaluation of modular models for consistency.  This notebook implements groupKfold on the training set and does not utilize the test set at all to avoid leakage during model evaluation and tuning.\n","\n","Note the channel specific version of this was forked on 1/31/2023 as Evaluate_Channels_PSG-Audio.ipynb - in that notebook the code does more balancing of the dataset versus trying to push that to the model itself.\n","\n","This is intended to be an interactive Jupyter notebook and not a stand alone .py file as with some of the other load_data code.\n","\n","Author:  [Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), [IMICS Lab](https://imics.wp.txstate.edu/), Texas State University, 2023\n","\n","\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","TODO:\n","* This is very much an early version.\n","* Need to add f1 scores - despite dropping many \"normal\" to rebalance train the individual abnormal classes are still very unbalanced.\n","* Confusion matrix size needs to be adjusted and should also be converted to a figure to allow for saving to file."]},{"cell_type":"markdown","metadata":{"id":"6ZiY8knZYoDH"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1675267106221,"user_tz":360,"elapsed":5785,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["import os\n","import shutil\n","import time\n","from datetime import datetime\n","from datetime import date\n","from datetime import timedelta # for calculating training time\n","from random import randrange # for plotting samples\n","import numpy as np\n","import matplotlib.pyplot as plt # for plotting training curves\n","from tabulate import tabulate # for verbose tables, showing data\n","import tensorflow as tf\n","from tensorflow import keras #added to save model\n","from tensorflow.keras import layers #format matches MNIST example\n","from tensorflow.keras.callbacks import EarlyStopping\n","#imports for computing and displaying output metrics\n","import seaborn as sns\n","import pandas as pd\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.model_selection import GroupShuffleSplit\n","from sklearn.preprocessing import OneHotEncoder\n","import sys\n","import urllib.request # to get files from web w/o !wget\n","from shutil import unpack_archive # to unzip"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["my_dir = '.' # replace with absolute path if desired\n","interactive = True # runs simple calls for most cells\n","verbose = True\n","\n","working_dir = os.path.join(my_dir,'psg_dataset') # create local directory\n","if not os.path.exists(working_dir):\n","    os.mkdir(working_dir)"],"metadata":{"id":"6ojl3K0cn8Ub","executionInfo":{"status":"ok","timestamp":1675267113093,"user_tz":360,"elapsed":541,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Get small or full processed PSG-Audio numpy arrays\n","See PSG-Audio_load_dataset_for_multi-output.ipynb for info, this is source of the arrays.\n"],"metadata":{"id":"FGx6ZoRhXDkA"}},{"cell_type":"code","source":["use_small = True # arrays are 1/10th the size for shorter download/train time\n","if use_small:\n","    version = \"small\"\n","    flist = [\"small_x_train.npy\", \"small_y_train.npy\", \"small_sub_train.npy\"]\n","else:\n","    version = \"full\"\n","    flist = [\"x_train.npy\", \"y_train.npy\", \"sub_train.npy\"]"],"metadata":{"id":"Lt75AEST4k9B","executionInfo":{"status":"ok","timestamp":1675267117008,"user_tz":360,"elapsed":231,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Commented Out:  Get processed PSG-Audio numpy arrays from Zenodo sandbox\n","Note - the large files took over 8 hours to download on my Macbook at home.\n"],"metadata":{"id":"LO4pj_zT44B2"}},{"cell_type":"code","source":["def get_proc_psg_audio(ppsga_flist):\n","    \"\"\"checks for local file, if none downloads files in ppsga_flist from\n","     processed psg-audio repository on Zenodo into working_dir (global).\n","    :return: nothing\"\"\"\n","    ppsga_url = \"https://sandbox.zenodo.org/record/1144199\"\n","    for fname in flist:\n","        full_url = ppsga_url + \"/files/\" + fname\n","        ffname = os.path.join(working_dir, fname)\n","        if (os.path.exists(ffname)):\n","            if verbose:\n","                print (\"Local\",ffname,\"found, skipping download\")\n","        else:\n","            print(\"Downloading\",ffname,\"from\",full_url)\n","            urllib.request.urlretrieve(full_url, filename=ffname)\n","    return\n","if interactive:\n","    start_time = time.time()\n","    #get_proc_psg_audio(ppsga_flist = flist) # comment out to avoid accident...\n","    end_time = time.time()\n","    download_time = timedelta(seconds=(end_time - start_time))\n","    print('Total Download time =',(str(download_time).split(\".\")[0]), 'HH:MM:SS')"],"metadata":{"id":"tlKEXl-BSrLO","executionInfo":{"status":"ok","timestamp":1675192158693,"user_tz":360,"elapsed":33,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a79d6ef3-68f9-4369-d174-04126e53abf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Download time = 0:00:00 HH:MM:SS\n"]}]},{"cell_type":"markdown","source":["# Copy files from google drive (instead of Zenodo - much faster, less portable)"],"metadata":{"id":"OytU1_SGAZNY"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_rHOiy-koeo","executionInfo":{"status":"ok","timestamp":1675267152425,"user_tz":360,"elapsed":22713,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"e08aaaad-8945-48cb-db10-8a5ae2417184"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["dataset_dir = '/content/drive/MyDrive/Processed_Datasets/PSG-Audio/PSG_12ch_90_10_1s_1s'\n","for fname in flist:\n","        print(fname, end=' ')\n","        if (os.path.exists(os.path.join(working_dir, fname))):\n","            if verbose:\n","                print (\"Local\",fname,\"found, skipping download\")\n","        else:\n","            print(\"copying\")\n","            shutil.copy(os.path.join(dataset_dir, fname), working_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ke_h_2roJ05B","executionInfo":{"status":"ok","timestamp":1675267166940,"user_tz":360,"elapsed":10234,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"44653047-3daa-469d-8955-620353737aba"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["small_x_train.npy copying\n","small_y_train.npy copying\n","small_sub_train.npy copying\n"]}]},{"cell_type":"code","source":["def read_arrays():\n","    \"\"\"read in the arrays - leaving test arrays out of this for now (just tuning model)\"\"\"\n","    if use_small:\n","        print(\"Reading in small arrays\")\n","        X = np.load(os.path.join(working_dir, 'small_x_train.npy'))\n","        y = np.load(os.path.join(working_dir, 'small_y_train.npy'))\n","        sub = np.load(os.path.join(working_dir, 'small_sub_train.npy'))\n","    else:\n","        print(\"Reading in full arrays\")\n","        X = np.load(os.path.join(working_dir, 'x_train.npy'))\n","        y = np.load(os.path.join(working_dir, 'y_train.npy'))\n","        sub = np.load(os.path.join(working_dir, 'sub_train.npy'))\n","    print(\"Reading arrays from npy files\")\n","    headers = (\"Array\",\"shape\", \"data type\")\n","    mydata = [(\"X:\", X.shape, X.dtype),\n","            (\"y:\", y.shape, y.dtype),\n","            (\"sub:\", sub.shape, sub.dtype)]\n","    print(\"\\n\",tabulate(mydata, headers=headers))\n","    return X, y, sub\n","if interactive:\n","    X, y, sub = read_arrays()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VopGrU_0c5JF","executionInfo":{"status":"ok","timestamp":1675267167147,"user_tz":360,"elapsed":211,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"fef3882a-2422-4674-a510-15fab3df0cd3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading in small arrays\n","Reading arrays from npy files\n","\n"," Array    shape              data type\n","-------  -----------------  -----------\n","X:       (150216, 100, 12)  float32\n","y:       (150216, 2)        int8\n","sub:     (150216, 1)        uint16\n"]}]},{"cell_type":"markdown","source":["# Get flow and two respiratory bands Channels 9, 10, 11\n","This functionality has been moved into Evaluated_Channels_PSG-Audio.ipynb and will also be handled by the more complex models.\n","\n","The model_1d_cnn_dense below expects a more processed form of the data, specifically with only one label not two.\n"],"metadata":{"id":"3Mpdyqi8d9Hg"}},{"cell_type":"code","source":["model_dir = '/content/drive/MyDrive/Colab Notebooks/imics_lab_repositories/multi-output-psg/models'\n","model_fname = 'model_1d_cnn_dense.py'\n","#model_fname = 'model_1d_cnn_globavgpool.py'\n","\n","shutil.copy(os.path.join(model_dir, model_fname), my_dir)\n","\n","import model_1d_cnn_dense as my_model\n","#import model_1d_cnn_globavgpool as my_model\n","\n","print (\"Current model\",my_model.description)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPptA9QKwkPk","executionInfo":{"status":"ok","timestamp":1675214832577,"user_tz":360,"elapsed":190,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"fc365445-3e80-4a6a-e8ea-d8bce4b5cd40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current model 1D_CNN_Dense.py Concat input, 1D CNNs, with Dense Layers\n"]}]},{"cell_type":"code","source":["#my_model.MAX_EPOCHS = 6 # just to test the code"],"metadata":{"id":"P8dwBrQ419X7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rb7lzTOhjC5r"},"source":["## Run a stratified 5-fold group-based cross validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuS_0sBOjC5s"},"outputs":[],"source":["def run_cross_val():\n","    \"\"\"runs a five fold cross-validation pass. returns accuracy string\"\"\"\n","    print (\"running model\",my_model.description)\n","    print(\"Predicting\", labels, \"using\", ch_group)\n","\n","\n","    # Define per-fold score containers\n","    acc_per_fold = []\n","    loss_per_fold = []\n","    y_pred_per_fold = []\n","    y_test_per_fold = []\n","\n","    skf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    start_time = time.time()\n","\n","    for i, (train_index, test_index) in enumerate(skf.split(X, y, groups=sub)):\n","        print(f\"Fold {i}:\")\n","\n","        x_train, y_train = X[train_index], y[train_index]\n","        x_test, y_test = X[test_index], y[test_index]\n","        \n","        # One Hot Encode: Note for respiratory there are 5 relatively frequent\n","        # categories but others can appear in only a portion of the folds.\n","\n","        enc = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n","        y_train = enc.fit_transform(y_train)\n","        y_test = enc.transform(y_test)\n","\n","        model = my_model.build_model(x_train, y_train)\n","        history, model = my_model.train_model(model, x_train, y_train,\n","                                            x_test, y_test)  \n","        val_acc = history.history['val_accuracy'][-1]\n","        val_loss = history.history['val_loss'][-1] \n","\n","        acc_per_fold.append(val_acc * 100)\n","        loss_per_fold.append(val_loss)\n","\n","        # Generate predictions\n","        y_pred = model.predict(x_test, verbose = 0)\n","\n","        y_pred = np.argmax(y_pred, axis=1)\n","        y_pred_per_fold.append(y_pred)\n","        y_test_per_fold.append(np.argmax(y_test, axis=1))\n","\n","        # Plot training & validation loss values\n","        plt.plot(history.history['loss'])\n","        plt.plot(history.history['val_loss'])\n","        plt.title('Model loss')\n","        plt.ylabel('Loss')\n","        plt.xlabel('Epoch')\n","        plt.legend(['Train', 'Test'], loc='upper left')\n","        plt.show()\n","\n","    # == Provide average scores ==\n","    print('------------------------------------------------------------------------')\n","    print('Score per fold')\n","    for i in range(0, len(acc_per_fold)):\n","    #     print('------------------------------------------------------------------------')\n","        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]:4.2} - Accuracy: {acc_per_fold[i]:4.2f}%')\n","    print('------------------------------------------------------------------------')\n","    print('Average scores for all folds:')\n","    print(f'> Accuracy: {np.mean(acc_per_fold):4.2f} (+- {np.std(acc_per_fold):5.4})')\n","    acc_str = temp = str(f'> Accuracy: {np.mean(acc_per_fold):4.2f} (+- {np.std(acc_per_fold):5.4})')\n","    print('------------------------------------------------------------------------')\n","\n","    # Show total training time\n","    end_time = time.time()\n","    train_time = timedelta(seconds=(end_time - start_time))\n","    print('Total Training time =',(str(train_time).split(\".\")[0]), 'HH:MM:SS')\n","    # to plot confusion matrices return concat versions of y\n","    y_pred = np.concatenate(y_pred_per_fold)\n","    y_test = np.concatenate(y_test_per_fold)\n","    return acc_str, y_pred, y_test\n","result, y_pred, y_test = run_cross_val()\n","print (\"running model\",my_model.description)\n","print(\"Predicting\", labels, \"using\", ch_group)\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YThBqqsCjC5s"},"outputs":[],"source":["# == Confusion matrix ==\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","#moved to evaluate function\n","#y_pred = np.concatenate(y_pred_per_fold)\n","#y_test = np.concatenate(y_test_per_fold)\n","\n","print(classification_report(y_test, y_pred, target_names=class_names))\n","\n","cm = confusion_matrix(y_test, y_pred)\n","\n","def plot_confusion_matrix(cm, classes,\n","                            normalize=True,\n","                            title='Confusion matrix',\n","                            cmap=plt.cm.Blues):\n","        \"\"\"\n","        This function prints and plots the confusion matrix.\n","        Normalization can be applied by setting `normalize=True`.\n","        \"\"\"\n","        if normalize:\n","            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","            print(\"Normalized confusion matrix\")\n","            print(np.array(cm).round(2)) # to limit digits\n","        else:\n","            print('Confusion matrix, without normalization')\n","            print(cm)\n","    \n","        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","        plt.title(title)\n","        plt.colorbar()\n","        tick_marks = np.arange(len(classes))\n","        plt.xticks(tick_marks, classes,rotation=90)\n","        plt.yticks(tick_marks, classes)\n","    \n","        fmt = '.2f' if normalize else 'd'\n","        thresh = cm.max() / 2.\n","        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","            plt.text(j, i, format(cm[i, j], fmt),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","    \n","        plt.tight_layout()\n","        plt.ylabel('True label')\n","        plt.xlabel('Predicted label')\n","title = 'PSG-Audio Group 5-fold\\n'\n","title +=  \"Model: \" + my_model.description + '\\n'\n","title += \"Predicting \" + labels + \" using \" + ch_group + '\\n'\n","title += 'Accuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred))+'\\n'\n","plot_confusion_matrix(cm, classes=class_names, title=title, cmap='cubehelix_r')"]},{"cell_type":"markdown","source":["# STOP - the following code is to load the data from and save figures to google drive.\n","You are welcome to use it, but it is untested outside of my environment."],"metadata":{"id":"UZaWrZYVoYux"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1675199570311,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"},"user_tz":360},"id":"ETuyaCrYhU6z","outputId":"4b87477c-acee-4d1a-cb1a-2a777ec32289"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading load_data_utils.py from IMICS git repo\n"]}],"source":["def get_load_data_utils():\n","    \"\"\"checks for local file, if none downloads from IMICS repository.\n","    Assumes a global my_dir has been defined (default is my_dir = \".\")\n","    :return: nothing\"\"\"\n","    fname = 'load_data_utils.py'\n","    ffname = os.path.join(my_dir,fname)\n","    if (os.path.exists(ffname)):\n","        if verbose:\n","            print (\"Local load_data_utils.py found, skipping download\")\n","    else:\n","        print(\"Downloading\",fname, \"from IMICS git repo\")\n","        urllib.request.urlretrieve(\"https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/load_data_utils.py\", filename=fname)\n","if interactive:\n","    get_load_data_utils()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1675199572860,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"},"user_tz":360},"id":"OeQhR2vLI9hK","outputId":"445f37d1-f1bd-496d-c966-d0b1d8bf8690"},"outputs":[{"output_type":"stream","name":"stdout","text":["My env_info: \n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","GPU: name, driver_version, memory.total [MiB]\n","Tesla T4, 510.47.03, 15360 MiB\n","\n"]}],"source":["from load_data_utils import get_env_info\n","from load_data_utils import get_log_ffname\n","from load_data_utils import tabulate_numpy_arrays\n","from load_data_utils import channel_powerset\n","if interactive:\n","    print('My env_info: \\n' + get_env_info())"]},{"cell_type":"code","source":["save_log = False # set to False to avoid a problem if accidentally run...\n","# alternate confusion matrix with fig object to save\n","cm = confusion_matrix(y_test, y_pred)\n","cm_df = pd.DataFrame(cm,\n","                    index = class_names, \n","                    columns = class_names)\n","fig = plt.figure(figsize=(6.5,5))\n","sns.heatmap(cm_df, annot=True, fmt='d', cmap='cubehelix_r')\n","#plt.title('Insert title here\\n\n","#plt.title('Accuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\n","plt.title('Accuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.tight_layout() # keeps labels from being cutoff when saving as pdf\n","plt.show()\n","if save_log:\n","    log_ffname = get_log_ffname(\n","    log_file_dir = '/content/drive/My Drive/Colab_Run_Results',\n","    base_fname = \"PSG_Multi_Output_Work\")\n","    print(\"Saving results to\", log_ffname)\n","    with open(log_ffname, \"a\") as file_object:\n","        file_object.write(\"Generated by Evaluate_Model_PSG-Audio.ipynb\\n\")\n","        file_object.write(\"Processed PSG with 5 fold via sklearn GroupKFold\\n\")\n","        file_object.write(\"Final Accuracy: %0.3f\\n\" %accuracy_score(y_test, y_pred))\n","        file_object.write(\"Classification Report\\n\")\n","        file_object.write(classification_report(y_test, y_pred, target_names=class_names))\n","        file_object.write(\"Confusion Matrix\\n\")\n","        file_object.write(str(cm))\n","    cm_ffname = log_ffname.split('.')[0] + '_cm.pdf'\n","    print(\"saving cm plot as\",cm_ffname)\n","    fig.savefig(cm_ffname,format='pdf', dpi=1200)\n","    full_model_fname = log_ffname.split('.')[0] + '_model.txt'\n","    with open(full_model_fname, \"a\") as file_object:\n","        model.summary(print_fn=lambda x: file_object.write(x + '\\n'))\n","        #acknowledgement https://stackoverflow.com/users/14951382/sparklingdew\n","    #plot using keras function\n","    #ref https://keras.io/api/utils/model_plotting_utils/\n","    full_mplot_fname = log_ffname.split('.')[0] + '_model.png'\n","    keras.utils.plot_model(model, to_file=full_mplot_fname, show_shapes=True)"],"metadata":{"id":"Cg85VdOq40BR"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GOxTbOs80F2tQ1lgAJs11vJ7yVykSYXP","timestamp":1675181225453}],"authorship_tag":"ABX9TyNm/AfsunuLbVqQzELVLond"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5-r5TyJVldmZ"},"source":["# Model 1D CNN followed by Global Average Pooling\n","\n","A stand-alone model intended to be imported as a .py file.\n","\n","This version being used for PSG-Audio work.  Called by Evaluate_Model_PSG-Audio.ipynb.\n","\n","Author:  [Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), [IMICS Lab](https://imics.wp.txstate.edu/), Texas State University, 2023\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","TODO:\n","* "]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras #added to save model\n","from tensorflow.keras import layers #format matches MNIST example\n","from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"VbHmUnCE2_D9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["description = '1D_CNN_GlobAvgPool.py Concat input, 1D CNNs then Global Avg Pool'\n","\n","# Model params\n","k1_num_filters = 25\n","k1_size = 51\n","k2_num_filters = 50\n","k2_size = 9\n","dropout = 0.5\n","mpool_size = 8\n","\n","# Training params\n","BATCH_SIZE = 128\n","MAX_EPOCHS = 100\n","es_patience = 20 # early stopping patience\n","lrn_rate = 0.001 # learning rate, keras default is 0.001\n","lrn_verbose = 1 ##0 = silent, 1 = progress bar, 2 = one line per epoch\n","\n","def build_model(x_train, y_train):\n","    \"\"\"Builds 1D CNN followed by dense layer model.\n","    See .py for params.\n","    Returns: Model (Keras)\"\"\"\n","    n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n","    model = keras.Sequential(\n","        [\n","            layers.Input(shape=x_train[0].shape),\n","            layers.Conv1D(filters=k1_num_filters, kernel_size=k1_size, activation='relu',input_shape=(x_train.shape[0],x_train.shape[1])),\n","            layers.Conv1D(filters=k2_num_filters, kernel_size=k2_size, activation='relu'),\n","            layers.GlobalAveragePooling1D(),\n","            layers.Dense(y_train.shape[1], activation='softmax')\n","            ])\n","    return model\n","def train_model(model,x_train, y_train, x_test, y_test):\n","    # see https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n","    callback = EarlyStopping(monitor='val_loss', mode = 'min', patience=es_patience)\n","    opt = keras.optimizers.Adam(learning_rate=lrn_rate) # Keras default lr = 0.001\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","\n","    history = model.fit(\n","        x_train,y_train,\n","        batch_size = BATCH_SIZE,\n","        epochs=MAX_EPOCHS,\n","        callbacks=[callback],\n","        validation_data=(x_test,y_test),\n","        verbose = lrn_verbose) #0 = silent, 1 = progress bar, 2 = one line per epoch\n","    return history, model"],"metadata":{"id":"VNXy-ktw6lcx"},"execution_count":null,"outputs":[]}]}